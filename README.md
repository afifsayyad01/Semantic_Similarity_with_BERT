# Semantic_Similarity_with_BERT
This project impliments the BERT model (Biderctional Encoder Representation of Transformers) with hybrid pooling and bidirectional LSTM in order to give Similarity bewteen two input sentences as an output.(Internship work falicitated by EdTech Society).
The project is carrried out in 3 stages as GitHub learning, Data Science domain and last one is Overleaf Report writing.
